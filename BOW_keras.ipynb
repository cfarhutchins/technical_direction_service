{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOW_keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cfarhutchins/technical_direction_service/blob/master/BOW_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJKPYp6tYRQt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install GetOldTweets3\n",
        "pip install vaderSentiment"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rCn5NSosYmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "import GetOldTweets3 as got\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import re\n",
        "import nltk \n",
        "import bs4 as BeautifulSoup\n",
        "nltk.download('stopwords')\n",
        "import html5lib\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIUpmjJatejb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "5a3b9225-9703-478d-f127-6bc976e7f646"
      },
      "source": [
        "tweetCriteria = got.manager.TweetCriteria().setQuerySearch('reparations')\\\n",
        "                                           .setSince('2019-07-04')\\\n",
        "                                           .setUntil('2019-07-10')\\\n",
        "                                           .setMaxTweets(50_000)\n",
        "tweet = got.manager.TweetManager.getTweets(tweetCriteria)\n",
        "\n",
        "repar_tweets = []\n",
        "\n",
        "for i in tweet:\n",
        "  repar_tweets.append(i.text)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "An error occured during an HTTP request: HTTP Error 500: Internal Server Error\n",
            "Try to open in browser: https://twitter.com/search?q=reparations%20since%3A2019-07-04%20until%3A2019-07-10&src=typd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHHcdxhUvgx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "analyzer = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buluKu2ltecd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_repar = pd.DataFrame(repar_tweets)\n",
        "df_repar.rename(columns={0:'tweet'}, inplace= True)\n",
        "df_repar['feels'] = df_repar['tweet'].apply(lambda i: analyzer.polarity_scores(i))\n",
        "compound = []\n",
        "\n",
        "for dct in df_repar['feels']:\n",
        "  compound.append(dct['compound'])\n",
        "\n",
        "negative = []\n",
        "  \n",
        "for dct in df_repar['feels']:\n",
        "  negative.append(dct['neg'])\n",
        "  \n",
        "neutral = [] \n",
        "  \n",
        "for dct in df_repar['feels']:\n",
        "  neutral.append(dct['neu'])\n",
        "  \n",
        "positive = []\n",
        "\n",
        "for dct in df_repar['feels']:\n",
        "  positive.append(dct['pos'])\n",
        "  \n",
        "df_repar['compound'] = compound\n",
        "df_repar['negative'] = negative\n",
        "df_repar['neutral'] = neutral\n",
        "df_repar['positive'] = positive\n",
        "\n",
        "df_repar.drop(columns = 'feels', inplace = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FYu3LCSvviq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "af79aad8-8106-4612-868d-d24887be124a"
      },
      "source": [
        "df_repar.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>compound</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He needs to shut up. He wants google to provid...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@BarackObama was a good lesson for Black Ameri...</td>\n",
              "      <td>-0.5095</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where are my reparations?? https://www.globalr...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>But the 1 point that made the most sense which...</td>\n",
              "      <td>-0.8685</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Let's talk reparations: https://youtu.be/qSF95...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...  positive\n",
              "0  He needs to shut up. He wants google to provid...  ...     0.000\n",
              "1  @BarackObama was a good lesson for Black Ameri...  ...     0.076\n",
              "2  Where are my reparations?? https://www.globalr...  ...     0.000\n",
              "3  But the 1 point that made the most sense which...  ...     0.127\n",
              "4  Let's talk reparations: https://youtu.be/qSF95...  ...     0.000\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pY6OGJCSmRju",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.utils.validation import column_or_1d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_swP_L6VAbU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word = re.compile('[^\\s]+')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ogO0JvUUN-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "33904d2c-a4ff-4bcf-c3c5-f5455e013818"
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    #text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text\n",
        "    \n",
        "df_repar['clean_text'] = df_repar['tweet'].apply(clean_text)\n",
        "#print_plot(10)\n",
        "df_repar.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>compound</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He needs to shut up. He wants google to provid...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>needs shut wants google provide con content ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@BarackObama was a good lesson for Black Ameri...</td>\n",
              "      <td>-0.5095</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.076</td>\n",
              "      <td>barackobama good lesson black americans enemie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where are my reparations?? https://www.globalr...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>reparations https wwwglobalresearchca theirish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>But the 1 point that made the most sense which...</td>\n",
              "      <td>-0.8685</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.127</td>\n",
              "      <td>1 point made sense eventually led 2 reparation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Let's talk reparations: https://youtu.be/qSF95...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>lets talk reparations https youtube qsf95mcgwp4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...                                         clean_text\n",
              "0  He needs to shut up. He wants google to provid...  ...  needs shut wants google provide con content ti...\n",
              "1  @BarackObama was a good lesson for Black Ameri...  ...  barackobama good lesson black americans enemie...\n",
              "2  Where are my reparations?? https://www.globalr...  ...  reparations https wwwglobalresearchca theirish...\n",
              "3  But the 1 point that made the most sense which...  ...  1 point made sense eventually led 2 reparation...\n",
              "4  Let's talk reparations: https://youtu.be/qSF95...  ...    lets talk reparations https youtube qsf95mcgwp4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTm10eSOrZ7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_tags = ['reparations',\n",
        "           'slavery',\n",
        "           'descendants', \n",
        "           'stupid',\n",
        "           'civil war',\n",
        "           'ancestors',\n",
        "           'dead',\n",
        "           'hell',\n",
        "           'racism',\n",
        "           'abuse',\n",
        "           'shit',\n",
        "           'bitch',\n",
        "           'bullshit',\n",
        "           'vote',\n",
        "           'pay',\n",
        "           'pain',\n",
        "           'suffering',\n",
        "           'illegal aliens',\n",
        "           'dead',\n",
        "           'scam',\n",
        "           'chattel', \n",
        "           'forced',\n",
        "           'stealing',\n",
        "           'end',\n",
        "           'stealth',\n",
        "           'good',\n",
        "           'luck', \n",
        "           'happy',\n",
        "           'win', \n",
        "           'grandfathers',\n",
        "           'grandmothers',\n",
        "           'honestly',\n",
        "           'need',\n",
        "           'better',\n",
        "           'freedom',\n",
        "           'wealth', \n",
        "           'redistribution',\n",
        "           'support',\n",
        "           'public',\n",
        "           'forum',\n",
        "           'argument',\n",
        "           'peace',\n",
        "           'love',\n",
        "           'justice',\n",
        "           'claim'\n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh73ZZEtwU60",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5490324d-e5fd-4b12-8437-3e2a75825020"
      },
      "source": [
        "pingbit = pd.Series(my_tags)\n",
        "pingbit.head()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    reparations\n",
              "1        slavery\n",
              "2    descendants\n",
              "3         stupid\n",
              "4      civil war\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7l27uLDgIxIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzRBjIYpwUBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(ngram_range=(2,2),binary=True, stop_words='english')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afZ6lRGOwf-l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df_repar['tweet']\n",
        "y = df_repar['compound']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeurgsVm1o1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split, cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_dBYwqgsxCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= .33)\n",
        "\n",
        "X_train = cv.fit_transform(x_train)\n",
        "\n",
        "X_test = cv.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E56TwXh5xwT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "rdg = Ridge()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i0ipicCyHiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5UwZzs8yR8C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFihEbqAycKt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rdg.score(X_test, y_test)\n",
        "pingwords = cv.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__1bwZ7iyedw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pingwords = pd.DataFrame(rdg.coef_, index = pingwords).sort_values(by=0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tujnvA9naB4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ping_scores = []\n",
        "\n",
        "for data in df_pingwords[0]:\n",
        "  ping_scores.append(data)\n",
        "\n",
        "df_ping_scores = pd.DataFrame(ping_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xf3qXQK10tH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_ping_scores.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzKomtu213Ho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pingwords_lst = []\n",
        "\n",
        "for i in pingwords:\n",
        "  pingwords_lst.append(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGu2F6bBjswH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pingwords = df_pingwords.index\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-vIVDjysQex",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pingwords_lst = df_pingwords.to_list()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp8x-qTvs8Vz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pingwords = pd.DataFrame(pingwords_lst)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4moyUkYBtdj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pingwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU4-OGA8thvb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pingwords.rename(columns={0:'ping pair'}, inplace= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38JLvXy_uKoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_pingwords.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkw5bxeKRfu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_attention = df_pingwords.join(df_ping_scores)\n",
        "df_attention.rename(columns = {0:'score'}, inplace=True)\n",
        "#df_pingwords.rename(columns={0:'attention'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6B17Kz7Tmh2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_attention.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiD42rVsTmfT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "                                  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riKos3voTmcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxlFwl7ITGjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84Q-eSu-2doC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.validation import check_is_fitted\n",
        "from sklearn.utils.validation import column_or_1d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VliGuvL0_cP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYeCpS4fuuTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "c49ecd1f-ba9e-48b1-d3f8-d5feb790e837"
      },
      "source": [
        "train_size = int(len(df_repar) * .7)\n",
        "train_posts = df_repar['clean_text'][:train_size]\n",
        "train_tags = df_repar['compound'][:train_size]\n",
        "\n",
        "test_posts = df_repar['clean_text'][train_size:]\n",
        "test_tags = df_repar['compound'][train_size:]\n",
        "\n",
        "max_words = 1000\n",
        "tokenize = text.Tokenizer(num_words=max_words, char_level=False)\n",
        "tokenize.fit_on_texts(train_posts) # only fit on train\n",
        "\n",
        "x_train = tokenize.texts_to_matrix(train_posts)\n",
        "x_test = tokenize.texts_to_matrix(test_posts)\n",
        "\n",
        "\n",
        "encoder = TolerantLabelEncoder()\n",
        "encoder.fit(train_tags)\n",
        "y_train = encoder.transform(train_tags)\n",
        "y_test = encoder.fit_transform(test_tags)\n",
        "\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_shape=(max_words,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='Adagrad',\n",
        "              metrics=['accuracy'])\n",
        "              \n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15951 samples, validate on 1773 samples\n",
            "Epoch 1/2\n",
            " 3104/15951 [====>.........................] - ETA: 18s - loss: 5.9524 - acc: 0.2622"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-8b32586f1e4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     validation_split=0.1)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YuEWbaHqnWTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history.on_epoch_end(epoch= 'Epoch 12/12')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5e30cPs07z6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f698989c-f1fb-41bd-a008-f7c07a578722"
      },
      "source": [
        "\n",
        "history.model.predict(x_test)\n",
        "\n",
        "#model.predict(x_test)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.7501545e-08, 3.1909576e-07, 7.4528231e-08, ..., 6.3826334e-08,\n",
              "        9.9078527e-08, 2.3863764e-08],\n",
              "       [1.8744319e-09, 3.0489575e-09, 1.0331556e-09, ..., 5.2834519e-09,\n",
              "        1.0177007e-09, 3.9180690e-09],\n",
              "       [1.2511714e-09, 4.7972337e-10, 4.5640047e-10, ..., 6.3720279e-10,\n",
              "        1.0009170e-09, 5.1410716e-09],\n",
              "       ...,\n",
              "       [9.2204333e-09, 3.8032059e-08, 1.9962897e-08, ..., 4.6947026e-08,\n",
              "        3.1969691e-08, 2.7271682e-08],\n",
              "       [3.4061262e-10, 3.4958902e-10, 5.7367049e-09, ..., 2.8482179e-09,\n",
              "        7.2771994e-10, 4.3123033e-11],\n",
              "       [2.1282958e-07, 6.0935918e-07, 1.2954619e-07, ..., 3.8903593e-07,\n",
              "        1.6377267e-07, 3.8244952e-08]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcvUV4k6uuHt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da84fec4-1148-409f-b456-daa5171e2cf6"
      },
      "source": [
        "score = history.model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
        "print('Test accuracy:', score[0])"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7597/7597 [==============================] - 2s 293us/step\n",
            "Test accuracy: 13.7228929594471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaeNLDEBuL_t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "989e35e9-a10e-4f26-96fa-b7a34a1d93ca"
      },
      "source": [
        "df_repar.head()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>compound</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>He needs to shut up. He wants google to provid...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>needs shut wants google provide con content ti...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@BarackObama was a good lesson for Black Ameri...</td>\n",
              "      <td>-0.5095</td>\n",
              "      <td>0.189</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.076</td>\n",
              "      <td>barackobama good lesson black americans enemie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Where are my reparations?? https://www.globalr...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>reparations https wwwglobalresearchca theirish...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>But the 1 point that made the most sense which...</td>\n",
              "      <td>-0.8685</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.650</td>\n",
              "      <td>0.127</td>\n",
              "      <td>1 point made sense eventually led 2 reparation...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Let's talk reparations: https://youtu.be/qSF95...</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>lets talk reparations https youtube qsf95mcgwp4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  ...                                         clean_text\n",
              "0  He needs to shut up. He wants google to provid...  ...  needs shut wants google provide con content ti...\n",
              "1  @BarackObama was a good lesson for Black Ameri...  ...  barackobama good lesson black americans enemie...\n",
              "2  Where are my reparations?? https://www.globalr...  ...  reparations https wwwglobalresearchca theirish...\n",
              "3  But the 1 point that made the most sense which...  ...  1 point made sense eventually led 2 reparation...\n",
              "4  Let's talk reparations: https://youtu.be/qSF95...  ...    lets talk reparations https youtube qsf95mcgwp4\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWs7R-vO2BXL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "65fbb1fd-cf43-49a3-c3e5-6fbac9c688ed"
      },
      "source": [
        "word = re.compile('[^\\s]+', string= i)\n",
        "\n",
        "for word in df_pingwords['ping pair']:\n",
        "  print(word)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-05a7176a088f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[^\\s]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf_pingwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ping pair'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: compile() got an unexpected keyword argument 'string'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYpBtnJi2s8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySnbi7Wt8x8y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}